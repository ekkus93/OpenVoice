{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Accent and Multi-Lingual Voice Clone Demo with MeloTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from openvoice import se_extractor\n",
    "from openvoice.api import ToneColorConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "In this example, we will use the checkpoints from OpenVoiceV2. OpenVoiceV2 is trained with more aggressive augmentations and thus demonstrate better robustness in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_converter = 'checkpoints_v2/converter'\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "output_dir = 'outputs_v2'\n",
    "\n",
    "tone_color_converter = ToneColorConverter(f'{ckpt_converter}/config.json', device=device)\n",
    "tone_color_converter.load_ckpt(f'{ckpt_converter}/checkpoint.pth')\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Tone Color Embedding\n",
    "We only extract the tone color embedding for the target speaker. The source tone color embeddings can be directly loaded from `checkpoints_v2/ses` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reference_speaker = 'resources/example_reference.mp3' # This is the voice you want to clone\n",
    "target_se, audio_name = se_extractor.get_se(reference_speaker, tone_color_converter, vad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(reference_speaker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use MeloTTS as Base Speakers\n",
    "\n",
    "MeloTTS is a high-quality multi-lingual text-to-speech library by @MyShell.ai, supporting languages including English (American, British, Indian, Australian, Default), Spanish, French, Chinese, Japanese, Korean. In the following example, we will use the models in MeloTTS as the base speakers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melo.api import TTS\n",
    "\n",
    "texts = {\n",
    "    'EN_NEWEST': \"Did you ever hear a folk tale about a giant turtle?\",  # The newest English base speaker model\n",
    "    'EN': \"Did you ever hear a folk tale about a giant turtle?\",\n",
    "    'ES': \"El resplandor del sol acaricia las olas, pintando el cielo con una paleta deslumbrante.\",\n",
    "    'FR': \"La lueur dorée du soleil caresse les vagues, peignant le ciel d'une palette éblouissante.\",\n",
    "    'ZH': \"在这次vacation中，我们计划去Paris欣赏埃菲尔铁塔和卢浮宫的美景。\",\n",
    "    'JP': \"彼は毎朝ジョギングをして体を健康に保っています。\",\n",
    "    'KR': \"안녕하세요! 오늘은 날씨가 정말 좋네요.\",\n",
    "}\n",
    "\n",
    "\n",
    "src_path = f'{output_dir}/tmp.wav'\n",
    "\n",
    "# Speed is adjustable\n",
    "speed = 1.0\n",
    "\n",
    "output_files = []\n",
    "\n",
    "for language, text in texts.items():\n",
    "    model = TTS(language=language, device=device)\n",
    "    speaker_ids = model.hps.data.spk2id\n",
    "    \n",
    "    for speaker_key in speaker_ids.keys():\n",
    "        speaker_id = speaker_ids[speaker_key]\n",
    "        speaker_key = speaker_key.lower().replace('_', '-')\n",
    "        \n",
    "        source_se = torch.load(f'checkpoints_v2/base_speakers/ses/{speaker_key}.pth', map_location=device)\n",
    "        if torch.backends.mps.is_available() and device == 'cpu':\n",
    "            torch.backends.mps.is_available = lambda: False\n",
    "        model.tts_to_file(text, speaker_id, src_path, speed=speed)\n",
    "        save_path = f'{output_dir}/output_v2_{speaker_key}.wav'\n",
    "        \n",
    "        output_files.append(save_path)\n",
    "\n",
    "        # Run the tone color converter\n",
    "        encode_message = \"@MyShell\"\n",
    "        tone_color_converter.convert(\n",
    "            audio_src_path=src_path, \n",
    "            src_se=source_se, \n",
    "            tgt_se=target_se, \n",
    "            output_path=save_path,\n",
    "            message=encode_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(output_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(output_files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(output_files[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(output_files[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(output_files[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(output_files[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(output_files[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(output_files[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(output_files[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(output_files[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(output_files[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Small Incident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一件小事⑴\n",
    "# 鲁迅\n",
    "# From https://www.comp.nus.edu.sg/~tanhw/chinese/literature/lu-xun/yi-jian-xiao-shi.html?utm_source=chatgpt.com\n",
    "text_str = \"\"\"\n",
    "　　我从乡下跑到京城里，一转眼已经六年了。其间耳闻目睹的所谓国家大事\n",
    "，算起来也很不少；但在我心里，都不留什么痕迹，倘要我寻出这些事的影响\n",
    "来说，便只是增长了我的坏脾气，——老实说，便是教我一天比一天的看不起\n",
    "人。\n",
    "\n",
    "　　但有一件小事，却于我有意义，将我从坏脾气里拖开，使我至今忘记不得\n",
    "。\n",
    "\n",
    "　　这是民国六年的冬天，大北风刮得正猛，我因为生计关系，不得不一早在\n",
    "路上走。一路几乎遇不见人，好容易才雇定了一辆人力车，教他拉到Ｓ门去。\n",
    "不一会，北风小了，路上浮尘早已刮净，剩下一条洁白的大道来，车夫也跑得\n",
    "更快。刚近Ｓ门，忽而车把上带着一个人，慢慢地倒了。\n",
    "\n",
    "　　跌倒的是一个女人，花白头发，衣服都很破烂。伊从马路上突然向车前横\n",
    "截过来；车夫已经让开道，但伊的破棉背心没有上扣，微风吹着，向外展开，\n",
    "所以终于兜着车把。幸而车夫早有点停步，否则伊定要栽一个大斤斗，跌到头\n",
    "破血出了。\n",
    "\n",
    "　　伊伏在地上；车夫便也立住脚。我料定这老女人并没有伤，又没有别人看\n",
    "见，便很怪他多事，要自己惹出是非，也误了我的路。\n",
    "\n",
    "　　我便对他说，“没有什么的。走你的罢！”\n",
    "\n",
    "　　车夫毫不理会，——或者并没有听到，——却放下车子，扶那老女人慢慢\n",
    "起来，搀着臂膊立定，问伊说：\n",
    "\n",
    "　　“你怎么啦？”\n",
    "\n",
    "　　“我摔坏了。”\n",
    "\n",
    "　　我想，我眼见你慢慢倒地，怎么会摔坏呢，装腔作势罢了，这真可憎恶。\n",
    "车夫多事，也正是自讨苦吃，现在你自己想法去。\n",
    "\n",
    "　　车夫听了这老女人的话，却毫不踌躇，仍然搀着伊的臂膊，便一步一步的\n",
    "向前走。我有些诧异，忙看前面，是一所巡警分驻所，大风之后，外面也不见\n",
    "人。这车夫扶着那老女人，便正是向那大门走去。\n",
    "\n",
    "　　我这时突然感到一种异样的感觉，觉得他满身灰尘的后影，刹时高大了，\n",
    "而且愈走愈大，须仰视才见。而且他对于我，渐渐的又几乎变成一种威压，甚\n",
    "而至于要榨出皮袍下面藏着的“小”来。\n",
    "\n",
    "　　我的活力这时大约有些凝滞了，坐着没有动，也没有想，直到看见分驻所\n",
    "里走出一个巡警，才下了车。\n",
    "\n",
    "　　巡警走近我说，“你自己雇车罢，他不能拉你了。”\n",
    "\n",
    "　　我没有思索的从外套袋里抓出一大把铜元，交给巡警，说，“请你给他…\n",
    "…”\n",
    "\n",
    "　　风全住了，路上还很静。我走着，一面想，几乎怕敢想到自己。以前的事\n",
    "姑且搁起，这一大把铜元又是什么意思？奖他么？我还能裁判车夫么？我不能\n",
    "回答自己。\n",
    "\n",
    "　　这事到了现在，还是时时记起。我因此也时时煞了苦痛，努力的要想到我\n",
    "自己。几年来的文治武力，在我早如幼小时候所读过的“子曰诗云”⑵一般，\n",
    "背不上半句了。独有这一件小事，却总是浮在我眼前，有时反更分明，教我惭\n",
    "愧，催我自新，并且增长我的勇气和希望。\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_chinese_text_into_paragraphs_and_sentences(text):\n",
    "    \"\"\"\n",
    "    Splits Chinese text into paragraphs and then sentences within each paragraph.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input Chinese text.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of lists, where each inner list contains sentences from a paragraph.\n",
    "    \"\"\"\n",
    "    # Normalize full-width spaces and strip leading/trailing whitespace\n",
    "    text = text.replace('\\u3000', '').strip()\n",
    "\n",
    "    # Split into paragraphs by two or more newlines\n",
    "    paragraphs = re.split(r'\\n\\s*\\n', text)\n",
    "\n",
    "    paragraph_sentences = []\n",
    "    for paragraph in paragraphs:\n",
    "        # Remove excess internal newlines within paragraphs\n",
    "        paragraph = paragraph.replace('\\n', '')\n",
    "        # Split into sentences by Chinese punctuation (keep the punctuation)\n",
    "        sentences = re.split(r'(?<=[。！？])', paragraph)\n",
    "        # Remove empty strings and strip whitespace\n",
    "        sentences = [s.strip() for s in sentences if s.strip()]\n",
    "        paragraph_sentences.append(sentences)\n",
    "\n",
    "    return paragraph_sentences\n",
    "\n",
    "# Example usage:\n",
    "sentences_by_paragraph = split_chinese_text_into_paragraphs_and_sentences(text_str)\n",
    "\n",
    "# Display the results\n",
    "for i, paragraph in enumerate(sentences_by_paragraph):\n",
    "    print(f\"Paragraph {i+1}:\")\n",
    "    for j, sentence in enumerate(paragraph):\n",
    "        print(f\"  Sentence {j+1}: {sentence}\")\n",
    "    print(\"-\" * 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"ZH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = f'{output_dir}/tmp.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference_speaker = 'resources/example_reference.mp3' # This is the voice you want to clone\n",
    "reference_speaker = 'resources/fiona_zh.m4a'\n",
    "target_se, audio_name = se_extractor.get_se(reference_speaker, tone_color_converter, vad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_se = torch.load(f'checkpoints_v2/base_speakers/ses/zh.pth', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TTS(language=language, device=device)\n",
    "speaker_ids = model.hps.data.spk2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(speaker_ids.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_key = list(speaker_ids.keys())[0]\n",
    "speaker_id = speaker_ids[speaker_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio(save_path, text, output_dir, source_se, target_se, speaker_id):\n",
    "    src_path = f'{output_dir}/tmp.wav'\n",
    "\n",
    "    print(\"###save_path: \", save_path)\n",
    "    \n",
    "    if torch.backends.mps.is_available() and device == 'cpu':\n",
    "        torch.backends.mps.is_available = lambda: False\n",
    "    model.tts_to_file(text, speaker_id, src_path, speed=speed)\n",
    "\n",
    "    output_files.append(save_path)\n",
    "\n",
    "    # Run the tone color converter\n",
    "    encode_message = \"@MyShell\"\n",
    "    tone_color_converter.convert(\n",
    "        audio_src_path=src_path, \n",
    "        src_se=source_se, \n",
    "        tgt_se=target_se, \n",
    "        output_path=save_path,\n",
    "        message=encode_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio as ta\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Create directory for sentence wav files\n",
    "output_dir = \"sentences\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Synthesize each sentence and save to a file\n",
    "sentence_files = []\n",
    "sentence_count = 0\n",
    "for paragraph_index, paragraph_sentences in enumerate(sentences_by_paragraph):\n",
    "    for sentence_index, sentence in enumerate(paragraph_sentences):\n",
    "        # Ensure sentence is not empty after splitting\n",
    "        if sentence.strip():\n",
    "            sentence_count += 1\n",
    "            print(f\"Synthesizing sentence {sentence_count}: {sentence}\")\n",
    "            sentence = sentence.strip()\n",
    "            \n",
    "            file_path = os.path.join(output_dir, f\"sentence_{sentence_count}.wav\")\n",
    "            \n",
    "            generate_audio(file_path, sentence, output_dir, source_se, target_se, speaker_id)\n",
    "            \n",
    "            sentence_files.append(file_path)\n",
    "\n",
    "# Merge all sentence wav files\n",
    "merged_audio = None\n",
    "pause_duration_ms = 500  # Adjust the pause duration as needed (in milliseconds)\n",
    "paragraph_end_pause_ms = 1000 # Pause duration after each paragraph\n",
    "\n",
    "file_index = 0\n",
    "sentence_counter_for_paragraph = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paragraph_index, paragraph_sentences in enumerate(sentences_by_paragraph):\n",
    "    sentence_counter_for_paragraph = 0\n",
    "    for sentence_index, sentence in enumerate(paragraph_sentences):\n",
    "        if sentence.strip():\n",
    "            file_path = sentence_files[file_index]\n",
    "            print(file_path)\n",
    "            audio_segment = AudioSegment.from_wav(file_path)\n",
    "\n",
    "            if merged_audio is None:\n",
    "                merged_audio = audio_segment\n",
    "            else:\n",
    "                merged_audio += audio_segment\n",
    "\n",
    "            file_index += 1\n",
    "            sentence_counter_for_paragraph += 1\n",
    "\n",
    "    # Add a pause after each paragraph (if it's not the last paragraph)\n",
    "    if paragraph_index < len(sentences_by_paragraph) - 1:\n",
    "         # Add a pause at the end of the paragraph\n",
    "         pause = AudioSegment.silent(duration=paragraph_end_pause_ms)\n",
    "         if merged_audio is not None:\n",
    "            merged_audio += pause\n",
    "\n",
    "\n",
    "# Save the final merged audio\n",
    "if merged_audio is not None:\n",
    "    output_filename = \"A_Small_Incident.wav\"\n",
    "    merged_audio.export(output_filename, format=\"wav\")\n",
    "    print(f\"Merged audio saved as {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "Audio('A_Small_Incident.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvoice",
   "language": "python",
   "name": "condaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
